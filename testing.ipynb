{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama's Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import utils.sys_msgs as sys_msgs\n",
    "import bs4 as beautifulsoup\n",
    "import requests\n",
    "import trafilatura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_convo = [sys_msgs.assistant_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_or_not():\n",
    "    sys_msg = sys_msgs.INTERNET_SEARCH_CLASSIFIER_SYSTEM_MSG\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma3:4b-it-fp16',\n",
    "        messages=[{'role':'system','content':sys_msg}, assistant_convo[-1]]\n",
    "    )\n",
    "\n",
    "    content = response['message']['content']\n",
    "    print(f'SEARCH OR NOT: {content}')\n",
    "\n",
    "    if 'yes' in content.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator():\n",
    "    sys_msg = sys_msgs.SEARCH_QUERY_GENERATOR_SYSTEM_MSG\n",
    "\n",
    "    query_msg = f'CREATE A SEARCH QUERY FOR THIS PROMPT: \\n {assistant_convo[-1]}'\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma3:4b-it-fp16',\n",
    "        messages=[{'role':'system','content':sys_msg}, {'role': 'user', 'content': query_msg}]\n",
    "    )\n",
    "\n",
    "    content = response['message']['content']\n",
    "    print(f'QUERY GENERATOR: {content}')\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searxng_search(query):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "    }\n",
    "    # Use the searxng instance URL with query parameters.\n",
    "    url = 'http://localhost:4000/search'\n",
    "    params = {'q': query, 'format': 'html'}\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    results = []\n",
    "    \n",
    "    # Adjust the parsing based on searxng's HTML structure.\n",
    "    for i, result in enumerate(soup.find_all('div', class_='result'), start=1):\n",
    "        if i > 10:\n",
    "            break\n",
    "        \n",
    "        # Assume searxng uses a link with class 'result__title'\n",
    "        title_tag = result.find('a', class_='result__title')\n",
    "        if not title_tag:\n",
    "            continue\n",
    "        \n",
    "        link = title_tag.get('href')\n",
    "        # Assume the snippet is contained in a paragraph with class 'result__snippet'\n",
    "        snippet_tag = result.find('p', class_='result__snippet')\n",
    "        snippet = snippet_tag.get_text(strip=True) if snippet_tag else 'No description available'\n",
    "        \n",
    "        results.append({\n",
    "            'id': i,\n",
    "            'link': link,\n",
    "            'search_description': snippet\n",
    "        })\n",
    "        \n",
    "    print(f'SEARXNG SEARCH RESULTS: {results}\\n\\n')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duckduckgo_search(query):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.'\n",
    "    }\n",
    "    url = f'https://duckduckgo.com/html/?q={query}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = beautifulsoup.BeautifulSoup(response.text, 'html.parser')\n",
    "    results = []\n",
    "    for i, result in enumerate(soup.find_all('div', class_ = 'result'), start=1):\n",
    "        if i > 10:\n",
    "            break\n",
    "        title = result.find('a', class_='result__a')\n",
    "        if not title:\n",
    "            continue\n",
    "\n",
    "        link = title['href']\n",
    "        snippet_tag = result.find('a', class_='result__snippet')\n",
    "        snippet = snippet_tag.text.strip() if snippet_tag else 'No description available'\n",
    "\n",
    "        results.append({\n",
    "            'id': i,\n",
    "            'link': link,\n",
    "            'search_description': snippet\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_search_results(s_results, query):\n",
    "    sys_msg = sys_msgs.BEST_SEARCH_RESULT_SYSTEM_MSG\n",
    "    best_msg = f'SEARCH_RESULTS: {s_results} \\nUSER_PROMPT: {assistant_convo[-1]} \\nSEARCH_QUERY: {query}'\n",
    "\n",
    "    for _ in range(2):\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model='gemma3:4b-it-fp16',\n",
    "                messages=[{'role':'system','content':sys_msg}, {'role': 'user', 'content': best_msg}]\n",
    "            )\n",
    "            return response['message']['content']\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_webpage(url):\n",
    "    try:\n",
    "        downloaded = trafilatura.fetch_url(url)\n",
    "        return trafilatura.extract(downloaded, include_formatting=True,include_links=True)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_data_needed(search_content, query):\n",
    "    sys_msg = sys_msgs.CONTAINS_DATA_MSG\n",
    "    needed_prompt = f'PAGE_TEXT: {search_content} \\nUSER_PROMPT: {assistant_convo[-1]} \\nSEARCH_QUERY:{query}'\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model='gemma3:4b-it-fp16',\n",
    "        messages=[{'role':'system','content':sys_msg}, {'role': 'user', 'content': needed_prompt}]\n",
    "    )\n",
    "\n",
    "    content = response['message']['content']\n",
    "\n",
    "    if 'true' in content.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_search():\n",
    "    context = None\n",
    "    print(\"GENERATING SEARCH QUERY...\")\n",
    "    search_query = query_generator()\n",
    "\n",
    "    if search_query[0] == '\"':\n",
    "        search_query = search_query[1:-1]\n",
    "\n",
    "    search_results = searxng_search(search_query)\n",
    "    context_found = False\n",
    "\n",
    "    while not context_found and len(search_results) > 0:\n",
    "        best_result = best_search_results(search_results, search_query)\n",
    "        try:\n",
    "            page_link = search_results[best_result]['link']\n",
    "        except:\n",
    "            print('FAILED TO SELECT BEST SEARCH RESULT, TRYING AGAIN...')\n",
    "            continue\n",
    "\n",
    "        page_text = scrape_webpage(page_link)\n",
    "        search_results.pop(best_result)\n",
    "\n",
    "        if page_text and contains_data_needed(search_content=page_text, query=search_query):\n",
    "            context = page_text\n",
    "            context_found = True\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_assistant_response():\n",
    "    global assistant_convo\n",
    "    response = ollama.chat(model='gemma3:4b-it-fp16', messages=assistant_convo, stream = True)\n",
    "    complete_response = ''\n",
    "    print('Assistant:')\n",
    "\n",
    "    for chunk in response:\n",
    "        print(chunk['message']['content'], end='',flush=True)\n",
    "        complete_response += chunk['message']['content']\n",
    "    assistant_convo.append({'role': 'assistant','content':complete_response})\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global assistant_convo\n",
    "    \n",
    "    while True:\n",
    "        user_input = input('You:')\n",
    "        assistant_convo.append({'role': 'user', 'content': user_input})\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        if search_or_not():\n",
    "            context = ai_search()\n",
    "            assistant_convo = assistant_convo[:-1]\n",
    "\n",
    "            if context:\n",
    "                prompt = f'SEARCH RESULT: {context} \\n\\nUSER PROMPT: {user_input}'\n",
    "            else:\n",
    "                prompt = (\n",
    "                    f'USER PROMPT: In{user_input} \\n\\nFAILED SEARCH: \\nThe'\n",
    "                    'AI search model was unable to extract any reliable data. Explain that '\n",
    "                    'and ask if the user would like you to search again or respond '\n",
    "                    'without web search context. Do not respond if a search was needed '\n",
    "                    'and you are getting this message with anything but the above request'\n",
    "                    'of how the user would like to proceed.'\n",
    "                )\n",
    "            assistant_convo.append({'role': 'user', 'content': user_input})\n",
    "            \n",
    "        stream_assistant_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH OR NOT: Yes\n",
      "\n",
      "GENERATING SEARCH QUERY...\n",
      "QUERY GENERATOR: 2025 Chinese GP highlights race recap\n",
      "SEARXNG SEARCH RESULTS: []\n",
      "\n",
      "\n",
      "Assistant:\n",
      "Okay, please provide me with the search results for the 2025 Chinese Grand Prix. I need the text of the search results to be able to analyze them and give you a truly impressive and insightful summary. \n",
      "\n",
      "Once you paste the search results here, I’ll do my best to craft a compelling overview, highlighting key moments, driver performances, and any significant developments. Let's get those results!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
